use std::{borrow::Cow, cell::RefCell, path::Path};

use criterion::{criterion_group, criterion_main, Criterion};
use parol_runtime::{once_cell::sync::Lazy, TokenStream, Tokenizer};

const LEXER_INPUT: &str = include_str!("./input_1.txt");

// The regex generated by parol for `verly` grammar
const REGEX_1: &str = r#"(?P<G1>\r\n|\r|\n)|(?P<G2>[\s--\r\n]+)|(?P<G5>(?:(?:(?://.*(?:\r\n|\r|\n|$))|(?:(?ms)/\u{2a}.*?\u{2a}/))\s*)+)|(?P<G6>[0-9]+(?:_[0-9]+)*\.[0-9]+(?:_[0-9]+)*[eE][+-]?[0-9]+(?:_[0-9]+)*)|(?P<G7>[0-9]+(?:_[0-9]+)*\.[0-9]+(?:_[0-9]+)*)|(?P<G8>[0-9]+(?:_[0-9]+)*'[bodh][0-9a-fA-FxzXZ]+(?:_[0-9a-fA-FxzXZ]+)*)|(?P<G9>[0-9]+(?:_[0-9]+)*)|(?P<G10>'[01xzXZ])|(?P<G11>\-:)|(?P<G12>\->)|(?P<G13>\+:)|(?P<G14>\+=|-=|\*=|/=|%=|&=|\|=|\^=|<<=|>>=|<<<=|>>>=)|(?P<G15>\*\*)|(?P<G16>/|%)|(?P<G17>\+|-)|(?P<G18><<<|>>>|<<|>>)|(?P<G19><=|>=|<|>)|(?P<G20>===|==\?|!==|!=\?|==|!=)|(?P<G21>&&)|(?P<G22>\|\|)|(?P<G23>&)|(?P<G24>\^~|\^|~\^)|(?P<G25>\|)|(?P<G26>~&|~\||!|~)|(?P<G27>::)|(?P<G28>:)|(?P<G29>,)|(?P<G30>\$)|(?P<G31>\.\.)|(?P<G32>\.)|(?P<G33>=)|(?P<G34>\#)|(?P<G35>\{)|(?P<G36>\[)|(?P<G37>\()|(?P<G38>\})|(?P<G39>\])|(?P<G40>\))|(?P<G41>;)|(?P<G42>\*)|(?P<G43>\balways_comb\b)|(?P<G44>\balways_ff\b)|(?P<G45>\bassign\b)|(?P<G46>\basync_high\b)|(?P<G47>\basync_low\b)|(?P<G48>\bas\b)|(?P<G49>\bbit\b)|(?P<G50>\bcase\b)|(?P<G51>\bdefault\b)|(?P<G52>\belse\b)|(?P<G53>\benum\b)|(?P<G54>\bexport\b)|(?P<G55>\bf32\b)|(?P<G56>\bf64\b)|(?P<G57>\bfor\b)|(?P<G58>\bfunction\b)|(?P<G59>\bi32\b)|(?P<G60>\bi64\b)|(?P<G61>\bif_reset\b)|(?P<G62>\bif\b)|(?P<G63>\bimport\b)|(?P<G64>\binout\b)|(?P<G65>\binput\b)|(?P<G66>\binst\b)|(?P<G67>\binterface\b)|(?P<G68>\bin\b)|(?P<G69>\blocalparam\b)|(?P<G70>\blogic\b)|(?P<G71>\bmodport\b)|(?P<G72>\bmodule\b)|(?P<G73>\bnegedge\b)|(?P<G74>\boutput\b)|(?P<G75>\bpackage\b)|(?P<G76>\bparameter\b)|(?P<G77>\bposedge\b)|(?P<G78>\bref\b)|(?P<G79>\brepeat\b)|(?P<G80>\breturn\b)|(?P<G81>\bstep\b)|(?P<G82>\bstruct\b)|(?P<G83>\bsync_high\b)|(?P<G84>\bsync_low\b)|(?P<G85>\btri\b)|(?P<G86>\bu32\b)|(?P<G87>\bu64\b)|(?P<G88>\bvar\b)|(?P<G89>[a-zA-Z_][0-9a-zA-Z_]*)|(?P<G90>.)"#;
// Manually modified regex that factors out the word boundaries
const REGEX_2: &str = r#"(?P<G1>\r\n|\r|\n)|(?P<G2>[\s--\r\n]+)|(?P<G5>(?:(?:(?://.*(?:\r\n|\r|\n|$))|(?:(?ms)/\u{2a}.*?\u{2a}/))\s*)+)|(?P<G6>[0-9]+(?:_[0-9]+)*\.[0-9]+(?:_[0-9]+)*[eE][+-]?[0-9]+(?:_[0-9]+)*)|(?P<G7>[0-9]+(?:_[0-9]+)*\.[0-9]+(?:_[0-9]+)*)|(?P<G8>[0-9]+(?:_[0-9]+)*'[bodh][0-9a-fA-FxzXZ]+(?:_[0-9a-fA-FxzXZ]+)*)|(?P<G9>[0-9]+(?:_[0-9]+)*)|(?P<G10>'[01xzXZ])|(?P<G11>\-:)|(?P<G12>\->)|(?P<G13>\+:)|(?P<G14>\+=|-=|\*=|/=|%=|&=|\|=|\^=|<<=|>>=|<<<=|>>>=)|(?P<G15>\*\*)|(?P<G16>/|%)|(?P<G17>\+|-)|(?P<G18><<<|>>>|<<|>>)|(?P<G19><=|>=|<|>)|(?P<G20>===|==\?|!==|!=\?|==|!=)|(?P<G21>&&)|(?P<G22>\|\|)|(?P<G23>&)|(?P<G24>\^~|\^|~\^)|(?P<G25>\|)|(?P<G26>~&|~\||!|~)|(?P<G27>::)|(?P<G28>:)|(?P<G29>,)|(?P<G30>\$)|(?P<G31>\.\.)|(?P<G32>\.)|(?P<G33>=)|(?P<G34>\#)|(?P<G35>\{)|(?P<G36>\[)|(?P<G37>\()|(?P<G38>\})|(?P<G39>\])|(?P<G40>\))|(?P<G41>;)|(?P<G42>\*)|(\b(?P<G43>always_comb)|(?P<G44>always_ff)|(?P<G45>assign)|(?P<G46>async_high)|(?P<G47>async_low)|(?P<G48>as)|(?P<G49>bit)|(?P<G50>case)|(?P<G51>default)|(?P<G52>else)|(?P<G53>enum)|(?P<G54>export)|(?P<G55>f32)|(?P<G56>f64)|(?P<G57>for)|(?P<G58>function)|(?P<G59>i32)|(?P<G60>i64)|(?P<G61>if_reset)|(?P<G62>if)|(?P<G63>import)|(?P<G64>inout)|(?P<G65>input)|(?P<G66>inst)|(?P<G67>interface)|(?P<G68>in)|(?P<G69>localparam)|(?P<G70>logic)|(?P<G71>modport)|(?P<G72>module)|(?P<G73>negedge)|(?P<G74>output)|(?P<G75>package)|(?P<G76>parameter)|(?P<G77>posedge)|(?P<G78>ref)|(?P<G79>repeat)|(?P<G80>return)|(?P<G81>step)|(?P<G82>struct)|(?P<G83>sync_high)|(?P<G84>sync_low)|(?P<G85>tri)|(?P<G86>u32)|(?P<G87>u64)|(?P<G88>var)\b)|(?P<G89>[a-zA-Z_][0-9a-zA-Z_]*)|(?P<G90>.)"#;

const MAX_K: usize = 3;
const ERROR_TOKEN_INDEX: usize = 90;

static TOKENIZERS_1: Lazy<Vec<(&'static str, Tokenizer)>> =
    Lazy::new(|| vec![("INITIAL", Tokenizer::with_regex(REGEX_1, 90).unwrap())]);

static TOKENIZERS_2: Lazy<Vec<(&'static str, Tokenizer)>> =
    Lazy::new(|| vec![("INITIAL", Tokenizer::with_regex(REGEX_2, 90).unwrap())]);

fn tokenize_1() {
    let file_name: Cow<Path> = Path::new("./input_1.txt").to_owned().into();
    let token_stream =
        RefCell::new(TokenStream::new(LEXER_INPUT, file_name, &TOKENIZERS_1, MAX_K).unwrap());
    while !token_stream.borrow().all_input_consumed() {
        let tok = token_stream.borrow_mut().lookahead(0).unwrap();
        assert_ne!(tok.token_type, ERROR_TOKEN_INDEX);
        token_stream.borrow_mut().consume().unwrap();
    }
}

fn tokenize_2() {
    let file_name: Cow<Path> = Path::new("./input_1.txt").to_owned().into();
    let token_stream =
        RefCell::new(TokenStream::new(LEXER_INPUT, file_name, &TOKENIZERS_2, MAX_K).unwrap());
    while !token_stream.borrow().all_input_consumed() {
        let tok = token_stream.borrow_mut().lookahead(0).unwrap();
        assert_ne!(tok.token_type, ERROR_TOKEN_INDEX);
        token_stream.borrow_mut().consume().unwrap();
    }
}

fn regex_1_benchmark(c: &mut Criterion) {
    c.bench_function("tokenize_1", |b| b.iter(|| tokenize_1()));
}

fn regex_2_benchmark(c: &mut Criterion) {
    c.bench_function("tokenize_2", |b| b.iter(|| tokenize_2()));
}

criterion_group!(benches, regex_1_benchmark, regex_2_benchmark);
criterion_main!(benches);
